{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5-final"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Exercise 5.2 - Solution",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QUgOoLu8DNHm"
      },
      "source": [
        "# Get the data\n",
        "\n",
        "First we need access to data.\n",
        "- You can use this link to add the data to your drive: https://drive.google.com/drive/folders/1pHNxZVrlcKh5usWoNC_V7gR2WdeDutjv\n",
        "- If you have not done this yet, right click on the **CS4MS_Data** folder and click on the **Add shortcut to Drive** option.\n",
        "- Inside the folder **CS4MS_Data** you will see the folder **HAM10000** - this is the dataset (set of images) we will be working with.\n",
        "\n",
        "Now you can run the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "94vUpD7sDNHm"
      },
      "source": [
        "# connect notebook to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LV5tr94SDNHn"
      },
      "source": [
        "data_dir = \"/content/drive/My Drive/CS4MS_Data/HAM10000\"\n",
        "\n",
        "classes = [ 'actinic keratoses', 'basal cell carcinoma', 'benign keratosis-like lesions',\n",
        "           'dermatofibroma','melanoma', 'melanocytic nevi', 'vascular lesions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pk1lLXEWDNHn"
      },
      "source": [
        "Quick example for object oriented programming: working with paths (folders and files)\n",
        "\n",
        "Documentation of this module: https://docs.python.org/3/library/pathlib.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x-g1LyoIDNHn"
      },
      "source": [
        "# import Path class from the pathlib module\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtPLN4YSDNHn"
      },
      "source": [
        "# make sure data is mounted\n",
        "assert Path(data_dir).is_dir(), 'you need to add the CS4MS folder to you google drive and mount it (go to top)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "t8YCKTxDDNHn"
      },
      "source": [
        "# create Path instance with path string from above\n",
        "p = Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EbBP9lhpDNHn"
      },
      "source": [
        "# get the name of folder / file\n",
        "p.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XT6fqjyzDNHn"
      },
      "source": [
        "# get the path objective of the parent folder\n",
        "p.parent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j8xcws8_DNHn"
      },
      "source": [
        "# does the folder nv exist in our path?\n",
        "(p / 'nv').exists()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7aBBqlpKDNHn"
      },
      "source": [
        "# how to iterate over the paths within a path?\n",
        "for child in p.iterdir():\n",
        "  print(child)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "u4NnQy4EDNHn"
      },
      "source": [
        "# how to iterate over specific files also within sub-folders?\n",
        "# cave: this might take a while since it is iterating through all subdirectories and files\n",
        "for path in p.glob('**/*.csv'):\n",
        "  print(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Zhod89SJDNHn"
      },
      "source": [
        "## About the data\n",
        "\n",
        "The HAM10000 (\"Human Against Machine with 10000 training images\") dataset which contains 10,015 dermatoscopic images was made publically available by the Harvard database on June 2018 in the hopes to provide training data for automating the process of skin cancer lesion classifications. The motivation behind this act was to provide the public with an abundance and variability of data source for machine learning training purposes such that the results may be compared with that of human experts. If successful, the appplications would bring cost and time saving regimes to hospitals and medical professions alike.\n",
        "\n",
        "Apart from the 10,015 images, a metadata file with demographic information of each lesion is provided as well. More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal)\n",
        "\n",
        "You can download the dataset here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T\n",
        "\n",
        "The 7 classes of skin cancer lesions included in this dataset are:\n",
        "\n",
        "- Melanocytic nevi\n",
        "- Melanoma\n",
        "- Benign keratosis-like lesions\n",
        "- Basal cell carcinoma\n",
        "- Actinic keratoses\n",
        "- Vascular lesions\n",
        "- Dermatofibroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4p5Ci92jDNHn"
      },
      "source": [
        "Let's analyze the metadata of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qygLc3b0DNHo"
      },
      "source": [
        "# import panda module for tabular data - https://pandas.pydata.org/docs/\n",
        "import pandas as pd\n",
        "\n",
        "# importing metadata and checking for its shape\n",
        "metadata = pd.read_csv(data_dir + '/HAM10000_metadata.csv')\n",
        "\n",
        "# label encoding the seven classes for skin cancers\n",
        "metadata['label'] = pd.Categorical(metadata[\"dx\"]).codes\n",
        "metadata.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fO3f0kX7DNHo"
      },
      "source": [
        "# numerical statistics\n",
        "metadata.describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6sgxhFTnDNHo"
      },
      "source": [
        "Plot of class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "T5HtSxYdDNHo"
      },
      "source": [
        "# import matplotlib module for plotting - https://matplotlib.org/3.2.1/contents.html\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Getting a sense of what the distribution of each column looks like\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "\n",
        "ax1 = fig.add_subplot(221)\n",
        "metadata['dx'].value_counts().plot(kind='bar', ax=ax1)\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Cell Type')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0lFDk_FUDNHo"
      },
      "source": [
        "Plot 5 images of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_6huWOfxDNHo"
      },
      "source": [
        "import imageio\n",
        "\n",
        "#Visualizing the images\n",
        "\n",
        "label = [ 'akiec', 'bcc','bkl','df','mel', 'nv',  'vasc']\n",
        "label_images = []\n",
        "classes = [ 'actinic keratoses', 'basal cell carcinoma', 'benign keratosis-like lesions',\n",
        "           'dermatofibroma','melanoma', 'melanocytic nevi', 'vascular lesions']\n",
        "\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "num_images = 5\n",
        "\n",
        "for i in label:\n",
        "    sample = metadata[metadata['dx'] == i]['image_id'][:num_images]\n",
        "    label_images.extend(sample)\n",
        "\n",
        "for position,ID in enumerate(label_images):\n",
        "    labl = metadata[metadata['image_id'] == ID]['dx']\n",
        "    im_sample = data_dir + \"/\" + labl.values[0] + f'/{ID}.jpg'\n",
        "\n",
        "    im_sample = imageio.imread(im_sample)\n",
        "\n",
        "    plt.subplot(7,num_images,position+1)\n",
        "    plt.imshow(im_sample)\n",
        "    plt.axis('off')\n",
        "\n",
        "    if position%5 == 0:\n",
        "        title = int(position/num_images)\n",
        "        plt.title(classes[title], loc='left', size=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7R_1NIMeDNHo"
      },
      "source": [
        "# Loading the data\n",
        "\n",
        "Use the **torchvision.datasets.ImageFolder** dataset class. This class requires the dataset to be arranged into folders of their respective class or labels. We already provide the dataset in suitable preprocessed format.\n",
        "\n",
        "Here we also apply the augmentation that we defined above.\n",
        "\n",
        "You can check here : https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Mh5J53EvDNHo"
      },
      "source": [
        "# import the torchvision module from the Pytorch framework\n",
        "# \"The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\"\n",
        "# documentation: https://pytorch.org/docs/stable/torchvision/index.html\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EZNrK2R0DNHo"
      },
      "source": [
        "Wait! Why is this module even available? It is not part of the list of default python module.\n",
        "\n",
        "Here's why: Google thinks you are most likely interested in machine learning and has the most popular frameworks preinstalled.\n",
        "\n",
        "You could install new modules with this command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z4AHdxG5DNHo"
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7hC8LJprDNHo"
      },
      "source": [
        "# create an instance of the image folder class to load images by classes defined with the folders given\n",
        "dataset = torchvision.datasets.ImageFolder(root= data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Za9CNxS7DNHo"
      },
      "source": [
        "Nice, that was easy. Now let's have a look at the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F3XUS1CUDNHo"
      },
      "source": [
        "# How many images are in the dataset?\n",
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w8dsLoyyDNHo"
      },
      "source": [
        "# Some useful attributes:\n",
        "print(f'folder names: {dataset.classes} ' +\n",
        "      f'\\n\\n number of classes:  {len(dataset.classes)}' +\n",
        "      f'\\n\\n dictionary with label (class) to encoding (target index): {dataset.class_to_idx}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "K3pVeTN7DNHo"
      },
      "source": [
        "# What type does the dataset's get item method return?\n",
        "type(dataset[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9rUgxg1oDNHo"
      },
      "source": [
        "type(dataset[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1vFaLZJDNHo"
      },
      "source": [
        "type(dataset[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfX7bEU0DNHo"
      },
      "source": [
        "# Let's separate the input and output\n",
        "image, label = dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RSa3Sr_cDNHo"
      },
      "source": [
        "# show image\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jydY87WtDNHo"
      },
      "source": [
        "# print label\n",
        "label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lpsgajI7DNHo"
      },
      "source": [
        "# What did those numbers mean again?\n",
        "classes[label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HITFTcuzDNHo"
      },
      "source": [
        "# little helper to show the data points\n",
        "def show_data_entry(data):\n",
        "  image, label = data\n",
        "  print(f\"Image Shape: {image.size} \\n Label: {label} \\n Lesion Type: {classes[label]}\")\n",
        "  return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d0j4cIsuDNHp"
      },
      "source": [
        "# let's play with this a bit\n",
        "show_data_entry(dataset[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "uF-TGx2mDNHp"
      },
      "source": [
        "# Train, Test and Validation Split\n",
        "It is a best practice to split the entire dataset into 3 parts:\n",
        "- Train: Used to train a network.\n",
        "- Validation: Fine tune the network.\n",
        "- Test: Kept as unseen data to gauge the performance of out trained network.\n",
        "\n",
        "\n",
        "The splitting should be done class wise so that we have equal representation of all classes in each subset of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1HF2uyhyDNHp"
      },
      "source": [
        "# import of the main Pytorch module - see: https://pytorch.org/docs/stable/torch.html\n",
        "# \"The torch package contains data structures for multi-dimensional tensors and mathematical operations over these are defined. Additionally, it provides many utilities for efficient serializing of Tensors and arbitrary types, and other useful utilities.\"\n",
        "import torch\n",
        "\n",
        "# import the numpy module a powerful package for scientific computing\n",
        "# https://numpy.org/doc/stable/\n",
        "import numpy as np\n",
        "\n",
        "#import a helpful method for splitting the dataset from SciKit Learn - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ozbrw3ZWDNHp"
      },
      "source": [
        "# get the total amount of images in the dataset\n",
        "num_images = len(dataset)\n",
        "\n",
        "# create a list of indices for the whole dataset\n",
        "indices = np.arange(num_images)\n",
        "\n",
        "# get the class labels from the dataset object (0-6)\n",
        "class_labels = dataset.targets\n",
        "\n",
        "# define the percentage of data that is not used for training\n",
        "split_size = 0.2\n",
        "\n",
        "# call a function of sklarn that takes care of splitting the dataset into training and validation+testing\n",
        "train_indices, test_indices = train_test_split(indices,\n",
        "                                               test_size=split_size,\n",
        "                                               shuffle=True,\n",
        "                                               stratify= class_labels,\n",
        "                                               random_state=42)\n",
        "\n",
        "# call a function of sklearn that splits validation+testing into validation and testing\n",
        "train_indices, val_indices = train_test_split(train_indices,\n",
        "                                               test_size=split_size,\n",
        "                                               shuffle=True,\n",
        "                                               stratify= np.asarray(class_labels)[train_indices],\n",
        "                                               random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CoBa6rT_DNHp"
      },
      "source": [
        "Now, we have our dataset loaded! Next week we will look into data loaders, augmentation and how to apply the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "aggSa8NFDNHp"
      },
      "source": [
        "# Hausaufgabe\n",
        "\n",
        "1. Count the appearance of each class in the different splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFQz69BrDNHp"
      },
      "source": [
        "# create a dictionary containing the list of indices for each dataset split\n",
        "indices_dict = {\n",
        "    'train': train_indices,\n",
        "    'val': val_indices,\n",
        "    'test': test_indices\n",
        "}\n",
        "print(indices_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDxv2eKaDNHp"
      },
      "source": [
        "# another dictionary to save the count of each class for the 3 dataset splits\n",
        "class_count = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8eac8xIDNHp"
      },
      "source": [
        "# loop through the index lists - split is the key of the dictionary\n",
        "# with .items() a dictionary can bee looped through\n",
        "for split, indices_list in indices_dict.items():\n",
        "  print(f'counting classes in {split}')\n",
        "  # set the count of each class to 0\n",
        "  class_count[split] = [0 for i in range(len(dataset.classes))]\n",
        "  for index in indices_list:\n",
        "    # get dataset item for each index in the split\n",
        "    # dataset.targets contains only the label with is computationally more efficient\n",
        "    label = dataset.targets[index]\n",
        "    \n",
        "    # this would also work but is a lot slower since every image is accessed\n",
        "    # _, label = dataset[index]\n",
        "    # _ discards the image since we are only interested in the label\n",
        "    \n",
        "    # increase the count of the label by one\n",
        "    class_count[split][label] += 1\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU-HevefDNHp"
      },
      "source": [
        "# print the result\n",
        "print(class_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yICbWp1ZDNHp"
      },
      "source": [
        "# now did the stratified shuffle split work? i.e. the distribution of the classes per split are the same?\n",
        "for split, counts in class_count.items():\n",
        "  normalized_counts = [count / max(counts) for count in counts]\n",
        "  print(normalized_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rD8vcLO_DNHp"
      },
      "source": [
        ""
      ]
    }
  ]
}