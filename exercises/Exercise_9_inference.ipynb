{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_9_inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvzaQlIqOyXc"
      },
      "source": [
        "## Exercise 9 Inference of Skin Leasion\n",
        "\n",
        "We will use a pre trained model for Skin Leasion classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji3MQZ9KQOh7"
      },
      "source": [
        "# Imports\n",
        "# import libraries for simple image plotting and \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision as torchvision\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7TnokUcOmsE"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awTvDmueRsMS"
      },
      "source": [
        "norm_mean = (0.485, 0.456, 0.406)\n",
        "norm_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Standard transform we learned in the last lecture\n",
        "cat_transform = transforms.Compose([\n",
        "                                  # resize image to the network input size\n",
        "                                  transforms.Resize((224,224)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(norm_mean, norm_std),\n",
        "                                   ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5Y967dIQ2VN"
      },
      "source": [
        "classes = [ 'actinic keratoses', 'basal cell carcinoma', 'benign keratosis-like lesions', \n",
        "           'dermatofibroma','melanoma', 'melanocytic nevi', 'vascular lesions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Y7mvjYScEy"
      },
      "source": [
        "## Loading a Neural Network\n",
        "model = torchvision.models.resnet18(pretrained = False) # This is a very well known network but it is designed for 1000 classes and not just cats and dogs this is why we need the next line\n",
        "model.fc = nn.Linear(512,len(classes)) \n",
        "\n",
        "state_dict_trained = torch.hub.load_state_dict_from_url('https://github.com/IFL-CAMP/AI4MDs_21/raw/main/checkpoints/ham10k_83.pth', model_dir=\".\", map_location = device) # This is a checkpoint to a trained cat and dog model that works pretty well\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC_trT_3FmWq"
      },
      "source": [
        "model.load_state_dict(state_dict_trained) ## Here we load the trained weights (state_dict) in our model \n",
        "model.eval() # This puts our model in eval mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTsNBXpNDjnr"
      },
      "source": [
        "!wget https://4ag46i294nta1038p13v77x1-wpengine.netdna-ssl.com/wp-content/uploads/basal-cell-carcinoma-2-open-sore.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RatQaG_eE8yK"
      },
      "source": [
        "norm_mean = (0.485, 0.456, 0.406)\n",
        "norm_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Standard transform we learned in the last lecture\n",
        "transform_ham = transforms.Compose([\n",
        "                                  # resize image to the network input size\n",
        "                                  transforms.Resize((224,224)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(norm_mean, norm_std),\n",
        "                                   ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFRkY8sREPIO"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def denorm(img):\n",
        "    img[0,:,:] = (img[0,:,:] * np.asarray(norm_std[0])) + np.asarray(norm_mean[0])\n",
        "    img[1,:,:] = (img[1,:,:] * np.asarray(norm_std[1])) + np.asarray(norm_mean[1])\n",
        "    img[2,:,:] = (img[2,:,:] * np.asarray(norm_std[2])) + np.asarray(norm_mean[2])\n",
        "    return img\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.clone().numpy()\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.axis('off')\n",
        "    ax.imshow(np.transpose(denorm(npimg), (1, 2, 0)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRTMKo78J37S"
      },
      "source": [
        "def show_result(outputs, leasion_tensor):\n",
        "    pred = torch.argmax(outputs, dim=1).cpu().numpy() \n",
        "    imshow(torchvision.utils.make_grid(leasion_tensor))\n",
        "    out_txt= f\"\\n--------------------------\\n\\n Predicted: {classes[pred[0]]}\\n Class: {pred[0]}\\n\"\n",
        "    if pred == 1 or pred == 4:\n",
        "      out_txt += f\" Recommendation: CHECK WITH YOUR MD!\"\n",
        "    else:\n",
        "      out_txt += f\" Recommendation: Nothing to be worried about.\"\n",
        "    out_txt+=\"\\n--------------------------\"\n",
        "    print(out_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcM1ISBzEbOq"
      },
      "source": [
        "fileName = \"basal-cell-carcinoma-2-open-sore.png\"\n",
        "leasionExample = Image.open(fileName).convert('RGB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj-3d38uEr4T"
      },
      "source": [
        "leasion_tensor = transform_ham(leasionExample)\n",
        "leasion_tensor = leasion_tensor.unsqueeze(dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd35b1sESkKC"
      },
      "source": [
        "# Lets try the model\n",
        "with torch.no_grad(): # during testing we dont learn so we dont need to calculate the gradient for learning\n",
        "  outputs=model(leasion_tensor) # That is a forward pass to a network\n",
        "outputs = torch.exp(outputs) # transform the output to probabilities\n",
        "pred = torch.argmax(outputs, dim=1).cpu().numpy()  # here we take the highest probabily and get the index 0 was cat and 1 was dog\n",
        "\n",
        "show_result(outputs, leasion_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLEe1PbmIexx"
      },
      "source": [
        "# Webcam example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRBzRY7eIWIo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPeDnaW92A60"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY2Y4nYf2MN2"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoIbJz1W2MN3"
      },
      "source": [
        "from IPython.display import Image as Image_py\n",
        "try:\n",
        "  filename_webcam = take_photo()\n",
        "  print('Saved to {}'.format(filename_webcam))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image_py(filename_webcam))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFdrqY5bImuL"
      },
      "source": [
        "\n",
        "leasionExample = Image.open(filename_webcam).convert('RGB')\n",
        "\n",
        "leasion_tensor = transform_ham(leasionExample)\n",
        "leasion_tensor = leasion_tensor.unsqueeze(dim=0)\n",
        "\n",
        "# Lets try the model\n",
        "with torch.no_grad(): # during testing we dont learn so we dont need to calculate the gradient for learning\n",
        "  outputs=model(leasion_tensor) # That is a forward pass to a network\n",
        "pred = torch.argmax(outputs, dim=1).cpu().numpy()  # here we take the highest probabily and get the index 0 was cat and 1 was dog\n",
        "\n",
        "show_result(outputs, leasion_tensor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv3Vlgz52-Pg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}